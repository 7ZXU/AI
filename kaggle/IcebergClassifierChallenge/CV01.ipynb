{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1z9vpTSJEk3cQ1msjW8NpIytCzdtKrxFl",
      "authorship_tag": "ABX9TyOMALed2Vk4g+ezZkRz2UsU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7ZXU/AI/blob/main/kaggle/IcebergClassifierChallenge/CV01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLspASZ4BOaw"
      },
      "source": [
        "- 빙하와 배를 구분해내는 모델 세우는 문제\n",
        "- image classification\n",
        "- CNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfkDPN4E00rT"
      },
      "source": [
        "런타임 > 런타임유형 > GPU 속도 빠름"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0cHKd0YH2YZ"
      },
      "source": [
        "# 라이브러리 (=모듈)\n",
        "#특정 기능을 담은 프로그램\n",
        "#함수 or 클래스 포함\n",
        "\n",
        "#패키지\n",
        "#라이브러리 집합\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#numpy\n",
        "#수치 계산을 위해서 만들어진 라이브러리 (데이터 분석에 사용)\n",
        "\n",
        "#pandas\n",
        "#데이터 다루기 위한 라이브러리\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Scikit-Learn\n",
        "#파이썬 머신러닝 라이브러리 \n",
        "\n",
        "#sklearn.model_selection\n",
        "#mode_selection 패키지\n",
        "\n",
        "#train_test_split\n",
        "#train set 과 test set 분리 모듈\n",
        "\n",
        "import os\n",
        "#os.path\n",
        "#파일명과 파일경로에 대한 함수 제공\n",
        "\n",
        "#join\n",
        "#os.path.join(경로1, 경로2, 경로3, ...)\n",
        "#여러 경로 -> 하나의 경로로 이어줌\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "#matplotlib\n",
        "#그래프 그릴 때 사용되는 라이브러리\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "#3차원 그래프 그리는 데에 사용되는 모듈\n",
        "\n",
        "import pylab\n",
        "#Matplotlib\n",
        "#pyplot & pylab 모듈 포함\n",
        "\n",
        "##############질문################\n",
        "#왜 둘 다 import??\n",
        "#두 라이브러리의 함수 따로 사용\n",
        "\n",
        "#pyplot\n",
        "#사용자 인터페이스 제공\n",
        "#사용자가 보이지 않는 곳에서 명령을 받아 그래프 작성한 matplotlib\n",
        "#사용자의 명령에 따라 자동으로 그래프 그리는 pyplot\n",
        "\n",
        "#pylab\n",
        "#pyplot & numpy 하나의 namespace에 import\n",
        "\n",
        "plt.rcParams['figure.figsize']=10, 10\n",
        "#그림크기 (가로, 세로)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOOfcKm8gE0f",
        "outputId": "17b07bcc-846f-4f64-d178-4153dde3189a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "#mount : 드라이브 접근 허용\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oScvz8pdh2nz"
      },
      "source": [
        "data_path = os.path.dirname('/content/drive/MyDrive/colab/Statoil/')\n",
        "\n",
        "\n",
        "#경로복사"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X43ovs79Hm-0"
      },
      "source": [
        "target = is_iceberg\n",
        "\n",
        "iceberg == 1 (빙하)\n",
        "iceberg == 0 (배)\n",
        "\n",
        "\n",
        "HH : 수평 필터로 걸러냄\n",
        "HV : 수직 필터로 걸러냄"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgm6-qaOT6N3"
      },
      "source": [
        "\n",
        "train_path = os.path.join(data_path, \"train.json\")\n",
        "test_path = os.path.join(data_path, \"test.json\")\n",
        "###################\n",
        "#경로설정 오류\n",
        "\n",
        "train = pd.read_json(train_path)\n",
        "test = pd.read_json(test_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A9_9yODHmJ_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi6QECwsXDGc"
      },
      "source": [
        "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
        "\n",
        "#np.array(data)\n",
        "#X_band_1 array 선언\n",
        "\n",
        "#np.array.astype(자료형)\n",
        "#array 자료형 변환\n",
        "\n",
        "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
        "X_train = np.concatenate(\n",
        "    [X_band_1[:, :, :, np.newaxis], \n",
        "     X_band_2[:, :, :, np.newaxis], \n",
        "     ((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]\n",
        "     ], \n",
        "     axis=-1\n",
        ")\n",
        "\n",
        "#np.concatenate( , axis= )\n",
        "#배열을 하나로 합침\n",
        "#axis : 합치는 기준축\n",
        "#axis=0 : 첫번째 요소 기준으로 붙이기 (행)\n",
        "#axis=1 : 두번째 요소 기준으로 붙이기 (열)\n",
        "######newaxis########\n",
        "\n",
        "#axis=-1 : 마지막 축을 기준으로 붙임\n",
        "# 75 * 75 * 3(axis=-1) \n",
        "# 3차원 축을 기준으로 붙여줌\n",
        "\n",
        "#np.newaxis\n",
        "#차원 늘려줌\n",
        "#새로운 축 만들어줌\n",
        "\n",
        "#H : horizontal\n",
        "#V : vertical\n",
        "#HH\n",
        "#HV\n",
        "#avg\n",
        "\n",
        "#np.concatanete(a[:, :, np.newaxis], b[:, :, np.newaxis])\n",
        "#2차원(평면) -> newaxis 기준으로 붙임 -> 3차원(입체)\n",
        "\n",
        "#np.concatanete(a[:, :, :, np.newaxis], b[:, :, :, np.newaxis])\n",
        "#3차원(입체) -> newaxis 기준으로 붙임 -> 4차원(입체)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGLTsP5Ytu48"
      },
      "source": [
        "#Import Keras.\n",
        "from matplotlib import pyplot\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.models import Model\n",
        "from keras import initializers\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFHPyGPA2Xfm"
      },
      "source": [
        "#define model \n",
        "def getModel():\n",
        "  #building model\n",
        "  gmodel=Sequential()\n",
        "\n",
        "#딥러닝 = 퍼셉트론 + 숨겨진 퍼셉트론 층 쌓음\n",
        "#Sequential() : 퍼셉트론 층 만드는 함수\n",
        "  \n",
        "#Conv Layer 1\n",
        "  gmodel.add(Conv2D(64, kernel_size=(3, 3), activation = 'relu', input_shape=(75, 75, 3)))\n",
        "\n",
        "#gmodel.add() : 새로운 층을 추가하는 함수\n",
        "#마지막 층(출력층) + 나머지 층(은닉층)\n",
        "\n",
        "#CNN Convolution Neuron Network \n",
        "#입력된 이미지에 커널을 적용해서 특징을 한번 더 추출해낸다\n",
        "\n",
        "#커널의 각 칸에 가중치가 있음\n",
        "#따라서 기존 이미지에 가중치 곱해줌\n",
        "#커널을 적용해서 만들어진 층 = Convolution\n",
        "\n",
        "#Conv2D(커널 수, 커널 사이즈, 활성화함수, 입력값(행, 열, 색상=3/흑백=1))\n",
        "#Convolution 층 추가하는 함수\n",
        "\n",
        "  gmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "  gmodel.app(Dropout(0.2))\n",
        "\n",
        "#Pooling : 복잡한 내용 차원 축소 \n",
        "#MaxPooling : 정해진 구역에서 최댓값 추출 -> 차원 축소\n",
        "#AveragePooling : 정해진 구역에서 평균값 추출 -> 차원 축소\n",
        "\n",
        "#MaxPooling2D(pool_size(풀 창 크기), strides())\n",
        "#Dropout : 노드의 일부를 끔으로써 과적합 방지 (노드나 층이 너무 많으면 과적합 발생)\n",
        "\n",
        "   #Conv Layer 2\n",
        "  gmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
        "  gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  gmodel.add(Dropout(0.2))\n",
        "\n",
        "    #Conv Layer 3\n",
        "  gmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "  gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  gmodel.add(Dropout(0.2))\n",
        "\n",
        "    #Conv Layer 4\n",
        "  gmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "  gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  gmodel.add(Dropout(0.2))\n",
        "\n",
        "    #Flatten the data for upcoming dense layers\n",
        "  gmodel.add(Flatten())\n",
        "\n",
        "#Flatten() : 2차원 배열 -> 1차원 배열\n",
        "#########################\n",
        "#1차원으로 바꿔야 활성화 함수가 있는 층에서 사용 가능\n",
        "#Dense 1차원 배열이라 2차원이랑 곱할 수가 없음\n",
        "  \n",
        "    #Dense Layers\n",
        "  gmodel.add(Dense(512))    #은닉층 Dense   #노드수 512\n",
        "  gmodel.add(Activation('relu'))\n",
        "  gmodel.add(Dropout(0.2))\n",
        "\n",
        "    #Dense Layer 2\n",
        "  gmodel.add(Dense(256))\n",
        "  gmodel.add(Activation('relu'))\n",
        "  gmodel.add(Dropout(0.2))\n",
        "\n",
        "    #Sigmoid Layer  #출력층\n",
        "  gmodel.add(Dense(1))\n",
        "  gmodel.add(Activation('sigmoid'))\n",
        "  \n",
        "  mypotim=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "#경사하강법 : 가중치 업데이트 \n",
        "#고급경사하강법 : 모든 데이터를 다루기에 계산량이 많은 경사하강법의 단점 보완\n",
        "\n",
        "#[고급경사하강법1] 확률적 경사하강법 : 랜덤 추출된 데이터 사용하여 가중치 업데이트\n",
        "#[고급경사하강법2] 모멘텀 : 이전 업데이트와 같은 방향으로 일정 비율만 수정 -> 앞의 수정과 차이 줄임 -> 관성 유지\n",
        "#[고급경사하강법3] 아담 : Momentum(정확도) + RMSProp(보폭크기) 개선 -> 가장 많이 쓰이는 경사하강법\n",
        "\n",
        "  gmodel.compile(\n",
        "      loss='binary_crossentropy', \n",
        "      optimizer=mypotim,\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "#compile() : 모델이 구현될 환경 설정\n",
        "#loss : 오차함수 선택\n",
        "\n",
        "#loss = 'binary_crossentropy' (이항교차엔트로피)\n",
        "#분류문제(예측값=참(1) | 거짓(0)) 에서 사용 \n",
        "\n",
        "#교차 엔트로피 계열 함수\n",
        "#오차함수 = 평균 제곱 오차 계열 + 교차 엔트로피 계열\n",
        "#평균 제곱 오차 계열 = 수렴하기까지 속도 많이 걸림\n",
        "#교차 엔트로피 계열 = 출력값에 로그 취함 -> 오차up 속도up 오차down 속도down \n",
        "\n",
        "#######################\n",
        "#metrics() : 모델을 평가하는 지표 설정 + 평가 결과 보여줌 \n",
        "#metics['accuracy'] : 모델을 정확도로 평가 + 정확도 보여줌\n",
        "\n",
        "  gmodel.summary()\n",
        "  return gmodel \n",
        "\n",
        "def get_callbacks(filepath, patience=2):\n",
        "  es = EarlyStopping('val_loss', patience=patience, mode=\"min\") \n",
        "  msave = ModelCheckpoint(filepath, save_best_only=True)\n",
        "  return [es, msave]\n",
        "\n",
        "#callback : loss 더 이상 줄지 않을 때 학습 종료\n",
        "\n",
        "#epoch : 반복 횟수\n",
        "#EarlyStopping(모니터링할 값, 기다릴 횟수, 모니터링할 값 최소화시켜야함) \n",
        "#val_loss : validation set의 loss\n",
        "#성능이 증가하지 않는다고(테스트 오차가 줄지 않음) 판단 후 patience 횟수만큼 기다렸다 학습 중단\n",
        "#############class 공부 필요################\n",
        "#EarlyStopping = class -> 멈추는 것에 대한 함수 불러옴\n",
        "\n",
        "#ModelCheckpoint(저장경로, 앞의 모델모다 나아졌을때만 저장하라)\n",
        "#모니터할 값 val_loss(테스트 오차) 반환\n",
        "\n",
        "file_path = \".model_weights.hdf5\" #hdf5 #학습결과에 대한 모든 값 저장\n",
        "callbacks = get_callbacks(filepath=file_path, patience=5) #######patience 재설정?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KehfwFu8VZh"
      },
      "source": [
        "target_train=train['is_iceberg']\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, target_train, random_state=1, train_size=0.8)\n",
        "\n",
        "#train set -> train set + valid set\n",
        "#바로 test하지 않고  valid set으로 과적합 판단 후 test\n",
        "\n",
        "#train_test_split(data, target, random_state, train_size)\n",
        "#train_size : 훈련 셋 구성 비율\n",
        "#######random_state : 세트를 섞을 때  해당 값 보고 섞음, 하이퍼파라미터 튜닝 시 이 값을 고정하고 튜닝해야 데이터셋 변경 방지 가능\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFRjgMGAZnh6"
      },
      "source": [
        "#모델 실행 및 저장\n",
        "import os\n",
        "gmodel=getModel()\n",
        "gmodel.fit(X_train_cv, y_train_cv, \n",
        "           batch_size=24, \n",
        "           epochs=50, \n",
        "           verbose=1, \n",
        "           validation_data=(X_valid, y_valid),\n",
        "           callbacks=callbacks\n",
        ")\n",
        "\n",
        "#det getModel()\n",
        "#batch_size : 한번에 입력될 데이터 수 \n",
        "#verbose =1 : 학습 진행되는 과정 보여줌\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LORfcK6Idvlp"
      },
      "source": [
        "#저장된 weight 불러와서 loss, accuracy 확인\n",
        "gmodel.load_weights(filepath=file_path) #hdf5 #학습한 데이터에 대한 모든 정보 담고 있음 #학습한 가중치를 불러옴\n",
        "score=gmodel.evaluate(X_valid, y_valid, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test Accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckJKhxMJeLs5"
      },
      "source": [
        "predicted_test = gmodel.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxBXRZbbeSIl"
      },
      "source": [
        "#제출파일 만들기\n",
        "submission = pd.DataFrame()\n",
        "submission['id']=test['id']\n",
        "submission['is_iceberg']=predicted_test.reshape((predicted_test.shape[0]))\n",
        "submission.to_csv('sub.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}